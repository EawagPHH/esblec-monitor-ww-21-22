#Subset the new filtered df
df_per_alt = df_filtered %>% filter(wwtp == "ARA Altenrhein")
df_per_chu = df_filtered %>% filter(wwtp == "ARA Chur")
df_per_gen = df_filtered %>% filter(wwtp == "STEP d'Aïre Genève")
df_per_zur = df_filtered %>% filter(wwtp == "ARA Werdhölzli Zürich")
df_per_lug = df_filtered %>% filter(wwtp == "IDA CDA Lugano")
df_per_sen = df_filtered %>% filter(wwtp == "ARA Sensetal Laupen")
#Create a df without NAs for the variable total-E. coli loads
df_filtered_t = filter(df, !is.na(average_loads_tot_Ec))
#Subset the new filtered df
df_tot_alt = df_filtered_t %>% filter(wwtp == "ARA Altenrhein")
df_tot_chu = df_filtered_t %>% filter(wwtp == "ARA Chur")
df_tot_gen = df_filtered_t %>% filter(wwtp == "STEP d'Aïre Genève")
df_tot_zur = df_filtered_t %>% filter(wwtp == "ARA Werdhölzli Z?rich")
df_tot_lug = df_filtered_t %>% filter(wwtp == "IDA CDA Lugano")
df_tot_sen = df_filtered_t %>% filter(wwtp == "ARA Sensetal Laupen")
#Create a df without NAs for the variable ESBL-E. coli loads
df_filtered_r = filter(df, !is.na(average_loads_ESBL_Ec))
#Subset the new filtered df
df_ESBL_alt = df_filtered_r %>% filter(wwtp == "ARA Altenrhein")
df_ESBL_chu = df_filtered_r %>% filter(wwtp == "ARA Chur")
df_ESBL_gen = df_filtered_r %>% filter(wwtp == "STEP d'Aïre Genève")
df_ESBL_zur = df_filtered_r %>% filter(wwtp == "ARA Werdhölzli Zürich")
df_ESBL_lug = df_filtered_r %>% filter(wwtp == "IDA CDA Lugano")
df_ESBL_sen = df_filtered_r %>% filter(wwtp == "ARA Sensetal Laupen")
##Calculate overall statistics------------------------
# Define a function to calculate summary statistics
calculate_stats <- function(data, log_transform = FALSE, exclude_mean_sd = FALSE) {
if (log_transform) {
data <- log10(data)
}
mean_value <- ifelse(!exclude_mean_sd, mean(data, na.rm = TRUE), NA)
sd_value <- ifelse(!exclude_mean_sd, sd(data, na.rm = TRUE), NA)
median_value <- quantile(data, probs = 0.5, na.rm = TRUE)
quantile_values <- quantile(data, probs = c(0.25, 0.75), na.rm = TRUE)
min_value <- min(data, na.rm = TRUE)
max_value <- max(data, na.rm = TRUE)
return(list(mean = mean_value, sd = sd_value, median = median_value, quantiles = quantile_values, min = min_value, max = max_value))
}
# Define a function to format numbers in scientific notation
format_scientific <- function(x) {
formatted_values <- sapply(x, function(val) {
power <- floor(log10(abs(val)))
mantissa <- round(val / 10^power, 2)
if (power == 0) {
return(paste(mantissa, "x 10^0"))
} else {
return(paste(mantissa, "x 10^", power))
}
})
return(formatted_values)
}
# List of data frames
data_frames <- list("Switzerland" = df, "ARA Altenrhein" = df_alt, "ARA Chur" = df_chu,"STEP d'Aire Genève" = df_gen,"ARA Werdhölzli Zürich" = df_zur,
"IDA CDA Lugano" = df_lug,"ARA Sensetal Laupen" = df_sen)
# Define the variables for which you want to calculate summary statistics
variables <- c("average_ESBL_Ec", "average_loads_tot_Ec", "average_loads_ESBL_Ec", "average_counts_tot_Ec", "average_counts_ESBL_Ec")
# Define custom names for the variables in the output
variable_names <- c("ESBL-Ec Percentage", "Total-Ec Loads", "ESBL-Ec Loads", "Total-Ec Counts", "ESBL-Ec Counts")
# Variables for which to exclude mean and sd
exclude_mean_sd <- c("average_ESBL_Ec", "average_counts_tot_Ec", "average_counts_ESBL_Ec")
# Loop through data frames and variables to calculate and display summary statistics
for (data_frame_name in names(data_frames)) {
data_frame <- data_frames[[data_frame_name]]
cat("Data Frame:", data_frame_name, "\n")
for (i in 1:length(variables)) {
variable_name <- variables[i]
output_name <- variable_names[i]
log_transform <- variable_name %in% c("average_loads_tot_Ec", "average_loads_ESBL_Ec")
exclude_mean_sd_flag <- variable_name %in% exclude_mean_sd
stats <- calculate_stats(data_frame[[variable_name]], log_transform, exclude_mean_sd_flag)
formatted_min <- format_scientific(stats$min)
formatted_max <- format_scientific(stats$max)
formatted_median <- format_scientific(stats$median)
formatted_quantiles <- format_scientific(stats$quantiles)
cat(output_name, "- Mean:", ifelse(!exclude_mean_sd_flag, stats$mean, "NA"),
"- SD:", ifelse(!exclude_mean_sd_flag, stats$sd, "NA"), "- Median:", formatted_median,
"- 25th Quantile:", formatted_quantiles[1], "- 75th Quantile:", formatted_quantiles[2],
"- Min:", formatted_min, "- Max:", formatted_max, "\n")
}
cat("\n")
}
##Differences between WWTPs------
###Plots--------------------
####Percentage ESBL-E. coli-----------
#Order WWTPs in descending median percentage of ESBL-E. coli
m_o = c("STEP d'Aïre Genève", "IDA CDA Lugano","ARA Werdhölzli Zürich","ARA Altenrhein", "ARA Chur", "ARA Sensetal Laupen") #ordering WWTPs from highest to lowest percentage.
df$wwtp <- factor(df$wwtp, levels = m_o)
#Generate boxplot
perpl=ggplot(data=df) +
geom_boxplot(aes(y=(average_ESBL_Ec), x=wwtp), outlier.colour = NA, outlier.shape = NA) +
geom_point(aes(y=(average_ESBL_Ec), x=wwtp,
color = ifelse(is.na(esblEc_percentage_a) | is.na(esblEc_percentage_b), "Single replicate", "Averaged on two replicates"),
shape = ifelse(is.na(esblEc_percentage_a) | is.na(esblEc_percentage_b), "Single replicate", "Averaged on two replicates")),
position=position_jitter(width=0.1), size=1.9,alpha=0.6) +
theme(axis.text.x=element_text(angle=20, vjust=0.8, hjust=0.9, colour = "black"), axis.title.y=element_text(size=8.5),axis.text.y=element_text(colour="black"), legend.position="bottom") +
ylab(expression(paste("Percentage of ESBL- ", italic("E. coli"), " (%)"))) +
scale_color_manual(name="", values = c("Single replicate" = "darksalmon", "Averaged on two replicates" = "black"))+
scale_shape_manual(name="", values = c("Single replicate" = 17, "Averaged on two replicates" = 16))+
scale_y_continuous(breaks = c(1, 2, 3, 4,5))+
xlab("")
# calculate CDF
df = filter(df, !is.na(average_ESBL_Ec)) #remove na.values from dataset
CDF_list <- list() #Create a list to store CDF data for each wwtp
for (wwtp in unique(df$wwtp)) {
CDF_list[[wwtp]] <- ecdf(df$average_ESBL_Ec[df$wwtp == wwtp])
} # Iterate through each wwtp and calculate its CDF using ecdf()
df_CDF <- data.frame(x = seq(0, max(df$average_ESBL_Ec), length.out = 1000)) # Combine CDF data for all wwtps into a single data frame
for (wwtp in unique(df$wwtp)) {
df_CDF[, wwtp] <- CDF_list[[wwtp]](df_CDF$x)
}
df_CDF_long <- tidyr::gather(df_CDF, key = "wwtp", value = "CDF", -x) # Convert data from wide to long format for ggplot2
# Generate plot with CDF curves
custom_palette <- c("#fc8d62ff", "#8da0cbff", "#e78ac3ff", "#ffd92fff", "#a6d854ff", "#66c2a5ff") #line colours CDF plots
cdfper=ggplot(df_CDF_long, aes(x = x, y = CDF, color = wwtp)) +
geom_line(linewidth=1.2) +
theme_minimal()+
theme(legend.position= c(0.99, 0.9),legend.justification = c(1, 1))+
xlab(expression(paste("Percentage of ESBL- ", italic("E. coli"), " (%)"))) +
ylab("Cumulative Distribution Function") +
theme(axis.title.y = element_text(size=8.5), axis.title.x = element_text(size=9), axis.text.y = element_text(colour = "black"), axis.text.x = element_text(colour = "black"))+
scale_color_manual(values = custom_palette)+
labs(color = "WWTP")
####Loads ESBL-E. coli-----------
#Order WWTPs in descending median ESBL-E. coli loads
m_t = c("ARA Altenrhein","ARA Werdhölzli Zürich","STEP d'Aïre Genève", "ARA Sensetal Laupen", "ARA Chur", "IDA CDA Lugano") #ordering WWTPs from highest to lowest ESBL-Ec loads
#Generate boxplot
lrepl=ggplot(data=df) +
geom_boxplot(aes(y=log10(average_loads_ESBL_Ec), x=wwtp), outlier.colour = NA, outlier.shape = NA) +
geom_point(aes(y=log10(average_loads_ESBL_Ec), x=wwtp,
color = ifelse(is.na(esblEc_loads_a) | is.na(esblEc_loads_b), "Unique replicate", "Averaged on two replicates"),
shape = ifelse(is.na(esblEc_percentage_a) | is.na(esblEc_percentage_b), "Single replicate", "Averaged on two replicates")),
position=position_jitter(width=0.1), size=1.9,alpha=0.6) +
theme(axis.text.x=element_text(angle=20, vjust=0.8, hjust=0.9, colour = "black"), axis.title.y=element_text(size=8.5),axis.text.y=element_text(colour="black"), legend.position="none") +
ylab(expression(paste("loads ESBL- ", italic("E. coli"), " log10(CFUs/(person-day))"))) +
scale_color_manual(name="", values = c("Unique replicate" = "darksalmon", "Averaged on two replicates" = "black"))+
scale_shape_manual(name="", values = c("Single replicate" = 17, "Averaged on two replicates" = 16))+
scale_y_continuous(breaks = c(7, 8, 9), labels=c("7" = expression(10^{7}), "8" =expression(10^{8}),
"9" = expression(10^{9})))+
xlab("")
# calculate CDF
df = filter(df, !is.na(average_loads_ESBL_Ec)) #remove na.values from dataset
CDF_list <- list() #Create a list to store CDF data for each wwtp
for (wwtp in unique(df$wwtp)) {
CDF_list[[wwtp]] <- ecdf(log10(df$average_loads_ESBL_Ec)[df$wwtp == wwtp])
} # Iterate through each wwtp and calculate its CDF using ecdf()
df_CDF <- data.frame(x = seq(6.5, max(log10(df$average_loads_ESBL_Ec)), length.out = 1000)) # Combine CDF data for all wwtps into a single data frame
for (wwtp in unique(df$wwtp)) {
df_CDF[, wwtp] <- CDF_list[[wwtp]](df_CDF$x)
}
df_CDF_long <- tidyr::gather(df_CDF, key = "wwtp", value = "CDF", -x) # Convert data from wide to long format for ggplot2
# Generate plot with CDF curves
cdfesbl=ggplot(df_CDF_long, aes(x = x, y = CDF, color = wwtp)) +
geom_line(linewidth=1.2) +
theme_minimal()+
theme(legend.position= c(0.3, 0.9),legend.justification = c(1, 1))+
xlab(expression(paste("loads ESBL- ", italic("E. coli"), " log10(CFUs/(person-day))"))) +
ylab("Cumulative Distribution Function") +
scale_color_manual(values = custom_palette)+
labs(color = "WWTP")+
scale_x_continuous(breaks = c(7, 8, 9), labels=c("7" = expression(10^{7}), "8" =expression(10^{8}),
"9" = expression(10^{9}))) +
theme(axis.title.y = element_text(size=8.5), axis.title.x = element_text(size=9), axis.text.y = element_text(colour = "black"), axis.text.x = element_text(colour = "black"))
####Loads total E. coli-----------
#Order WWTPs in descending median total E. coli loads
m_l = c("ARA Altenrhein", "ARA Chur","ARA Sensetal Laupen","ARA Werdhölzli Zürich", "STEP d'Aïre Genève", "IDA CDA Lugano") #ordering WWTPs from highest to lowest total Ec loads
ltopl=ggplot(data=df) +
geom_boxplot(aes(y=log10(average_loads_tot_Ec), x=wwtp), outlier.colour = NA, outlier.shape = NA) +
geom_point(aes(y=log10(average_loads_tot_Ec), x=wwtp,
color = ifelse(is.na(totalEc_loads_a) | is.na(totalEc_loads_b), "Unique replicate", "Averaged on two replicates"),
shape = ifelse(is.na(esblEc_percentage_a) | is.na(esblEc_percentage_b), "Single replicate", "Averaged on two replicates")),
position=position_jitter(width=0.1), size=1.9, alpha=0.6) +
theme(axis.text.x=element_text(angle=20, vjust=0.8, hjust=0.9, colour = "black"), axis.title.y=element_text(size=8.5),axis.text.y=element_text(colour="black"), legend.position="none") +
ylab(expression(paste("loads total ", italic("E. coli"), " log10(CFUs/(person-day))"))) +
scale_color_manual(name="", values = c("Unique replicate" = "darksalmon", "Averaged on two replicates" = "black"))+
scale_shape_manual(name="", values = c("Single replicate" = 17, "Averaged on two replicates" = 16))+
scale_y_continuous(breaks = c(9, 10, 11), labels=c("9" = expression(10^{9}), "10" =expression(10^{10}),
"11" = expression(10^{11})))+
xlab("")
# calculate CDF
df = filter(df, !is.na(log10(average_loads_tot_Ec))) #remove na.values from dataset
CDF_list <- list()# Create a list to store CDF data for each wwtp
for (wwtp in unique(df$wwtp)) {
CDF_list[[wwtp]] <- ecdf(log10(df$average_loads_tot_Ec)[df$wwtp == wwtp])
} # Iterate through each wwtp and calculate its CDF using ecdf()
df_CDF <- data.frame(x = seq(8.5, max(log10(df$average_loads_tot_Ec)), length.out = 1000)) # Combine CDF data for all wwtps into a single data frame
for (wwtp in unique(df$wwtp)) {
df_CDF[, wwtp] <- CDF_list[[wwtp]](df_CDF$x)
}
df_CDF_long <- tidyr::gather(df_CDF, key = "wwtp", value = "CDF", -x) # Convert data from wide to long format for ggplot2
# Generate plot with CDF curves
cdftot=ggplot(df_CDF_long, aes(x = x, y = CDF, color = wwtp)) +
geom_line(linewidth=1.2) +
theme_minimal()+
theme(legend.position= c(0.3, 0.9),legend.justification = c(1, 1))+
xlab(expression(paste("loads total ", italic("E. coli"), " log10(CFUs/(person-day))"))) +
ylab("Cumulative Distribution Function") +
scale_color_manual(values = custom_palette)+
labs(color = "WWTP")+
scale_x_continuous(breaks = c(9, 10, 11), labels=c("9" = expression(10^{9}), "10" =expression(10^{10}),
"11" = expression(10^{11})))+
theme(axis.title.y = element_text(size=8.5), axis.title.x = element_text(size=9), axis.text.y = element_text(colour = "black"), axis.text.x = element_text(colour = "black"))
#Arrange all plots together (boxplots + CDF curves)
ggarrange(perpl, cdfper, ltopl, cdftot, lrepl, cdfesbl,nrow=3, ncol=2, labels=c("A", "B", "C", "D", "E", "F"), common.legend = TRUE)
# Perform the Kruskal-Wallis test
df_filtered$wwtp=as.factor(df_filtered$wwtp)
kruskal_test(average_ESBL_Ec ~ wwtp, data = df_filtered)
# perform pairwise comparisons using post-hoc test Dunn's test with "Bonferroni" correction to identify which groups differ significantly from each other.
dunn_test_result_perc_ESBLEc <- dunn.test(df_filtered$average_ESBL_Ec, df_filtered$wwtp,
method = "bonferroni")
dunn_test_result_perc_ESBLEc
# Perform the Kruskal-Wallis test
df_filtered_t$wwtp=as.factor(df_filtered_t$wwtp)
kruskal_test(average_loads_tot_Ec ~ wwtp, data = df_filtered_t)
# perform pairwise comparisons using post-hoc test Dunn's test with "Bonferroni" correction to identify which groups differ significantly from each other.
dunn_test_result_loads_totEc <- dunn.test(df_filtered_t$average_loads_tot_Ec, df_filtered_t$wwtp,
method = "bonferroni")
dunn_test_result_loads_totEc
# Perform the Kruskal-Wallis test
df_filtered_r$wwtp=as.factor(df_filtered_r$wwtp)
kruskal_test(average_loads_ESBL_Ec ~ wwtp, data = df_filtered_r)
# perform pairwise comparisons using post-hoc test Dunn's test with "Bonferroni" correction to identify which groups differ significantly from each other.
dunn_test_result_loads_ESBLEc <- dunn.test(df_filtered_r$average_loads_ESBL_Ec, df_filtered_r$wwtp,
method = "bonferroni")
dunn_test_result_loads_ESBLEc
##Differences between months-------------------------------
###Plots----------------------
####Percentage ESBL-E.coli----------------
per1=ggplot(data=df) +
geom_boxplot(aes(y=(average_ESBL_Ec), x=reorder(format(as.Date(date), "%b %Y"), date)), outlier.colour = NA, outlier.shape = NA) +
geom_point(aes(y=(average_ESBL_Ec), x=reorder(format(as.Date(date), "%b %Y"), date), color = ifelse(is.na(esblEc_percentage_a) | is.na(esblEc_percentage_b), "Single replicate", "Averaged on two replicates"), shape = ifelse(is.na(esblEc_percentage_a) | is.na(esblEc_percentage_b), "Single replicate", "Averaged on two replicates"))) +
facet_wrap(wwtp~., ncol=1) +
theme(axis.text.x=element_text(angle=90, vjust=1, hjust=1), axis.title.y=element_text(size=11),legend.position="bottom") +
ylab(expression(paste("Percentage of ESBL- ", italic("E. coli"), " (%)"))) +
scale_color_manual(name="", values = c("Single replicate" = "darksalmon", "Averaged on two replicates" = "black"))+
scale_shape_manual(name="", values = c("Single replicate" = 17, "Averaged on two replicates" = 16))+
scale_y_continuous(breaks = c(1, 2, 3, 4, 5))+
xlab("")
####Loads ESBL-E.coli----------------
lre1=ggplot(data=df) +
geom_boxplot(aes(y=log10(average_loads_ESBL_Ec), x=reorder(format(as.Date(date), "%b %Y"), date)), outlier.colour = NA, outlier.shape = NA) +
geom_point(aes(y=log10(average_loads_ESBL_Ec), x=reorder(format(as.Date(date), "%b %Y"), date), color = ifelse(is.na(esblEc_loads_a) | is.na(esblEc_loads_b), "Unique replicate", "Averaged on two replicates"), shape = ifelse(is.na(esblEc_percentage_a) | is.na(esblEc_percentage_b), "Single replicate", "Averaged on two replicates")), size=1.5) +
facet_wrap(wwtp~., ncol=1) +
theme(axis.text.x=element_text(angle=90, vjust=1, hjust=1), axis.title.y=element_text(size=11),legend.position="none") +
ylab(expression(paste("loads ESBL- ", italic("E. coli"), " log10(CFUs/(person-day))"))) +
scale_color_manual(name="", values = c("Unique replicate" = "darksalmon", "Averaged on two replicates" = "black"))+
scale_shape_manual(name="", values = c("Single replicate" = 17, "Averaged on two replicates" = 16))+
scale_y_continuous(breaks = c(7, 8, 9), labels=c("7" = expression(10^{7}), "8" =expression(10^{8}),
"9" = expression(10^{9})))+
xlab("")
####Loads total E.coli----------------
lto1=ggplot(data=df) +
geom_boxplot(aes(y=log10(average_loads_tot_Ec), x=reorder(format(as.Date(date), "%b %Y"), date)), outlier.colour = NA, outlier.shape = NA) +
geom_point(aes(y=log10(average_loads_tot_Ec), x=reorder(format(as.Date(date), "%b %Y"), date), color = ifelse(is.na(totalEc_loads_a) | is.na(totalEc_loads_b), "Unique replicate", "Averaged on two replicates"), shape = ifelse(is.na(esblEc_percentage_a) | is.na(esblEc_percentage_b), "Single replicate", "Averaged on two replicates")), size=1.5) +
facet_wrap(wwtp~., ncol=1) +
theme(axis.text.x=element_text(angle=90, vjust=1, hjust=1), axis.title.y=element_text(size=11), legend.position="none") +
ylab(expression(paste("loads total ", italic("E. coli"), " log10(CFUs/(person-day))"))) +
scale_color_manual(name="", values = c("Unique replicate" = "darksalmon", "Averaged on two replicates" = "black"))+
scale_shape_manual(name="", values = c("Single replicate" = 17, "Averaged on two replicates" = 16))+
scale_y_continuous(breaks = c(9, 10, 11), labels=c("9" = expression(10^{9}), "10" =expression(10^{10}),
"11" = expression(10^{11})))+
xlab("")
ggarrange(per1, lto1, lre1, ncol = 3, labels = c("A","B", "C"), common.legend = TRUE) #aggregate the three plots together
###Statistical tests--------------------
####Percentage ESBL-E.coli----------------
#Perform Kruskal-wallis with Dunn's test and Bonferroni adjustmen as a loop on all the WWTP df to check for significant differences on a monthly scale
df_list <- list(df_per_alt, df_per_chu, df_per_gen, df_per_sen, df_per_lug, df_per_zur) #Create a list of data frames for each wwtp
wwtp_names <- c("ARA Altenrhein", "ARA Chur", "STEP d'Aïre Genève", "ARA Sensetal Laupen",
"IDA CDA Lugano", "ARA Werdhölzli Zürich") #Define the names of the wwtps
for (i in seq_along(df_list)) {
# Perform the Kruskal-Wallis test
kruskal_test <- kruskal.test(average_ESBL_Ec ~ month_year, data = df_list[[i]])
# Perform the Dunn's test
dunn_test <- dunn.test(x = df_list[[i]]$average_ESBL_Ec, g = df_list[[i]]$month_year,
method = "bonferroni")
# Print the results for each wwtp
cat("\n====================\n")
cat(paste0("Results for ", wwtp_names[i], "\n"))
cat("====================\n\n")
# Print the Kruskal-Wallis test results
cat("Kruskal-Wallis Test:\n")
print(kruskal_test)
cat("\n")
# Print the Dunn's test results
cat("Dunn's Test:\n")
print(dunn_test$comparison)
cat("\n")
}
####Loads total E.coli----------------
#Perform Kruskal-wallis with Dunn's test and Bonferroni adjustmen as a loop on all the WWTP df to check for significant differences on a monthly scale
df_list <- list(df_tot_alt, df_tot_chu, df_tot_gen, df_tot_sen, df_tot_lug, df_tot_zur)#Create a list of data frames for each wwtp
wwtp_names <- c("ARA Altenrhein", "ARA Chur", "STEP d'Aïre Genève", "ARA Sensetal Laupen",
"IDA CDA Lugano", "ARA Werdhölzli Zürich")#Define the names of the wwtps
# Perform the Kruskal-Wallis test and Dunn's test for each wwtp
for (i in seq_along(df_list)) {
# Perform the Kruskal-Wallis test
kruskal_test <- kruskal.test(average_loads_tot_Ec ~ month_year, data = df_list[[i]])
# Perform the Dunn's test
dunn_test <- dunn.test(x = df_list[[i]]$average_loads_tot_Ec, g = df_list[[i]]$month_year,
method = "bonferroni")
# Print the results for each wwtp
cat("\n====================\n")
cat(paste0("Results for ", wwtp_names[i], "\n"))
cat("====================\n\n")
# Print the Kruskal-Wallis test results
cat("Kruskal-Wallis Test:\n")
print(kruskal_test)
cat("\n")
# Print the Dunn's test results
cat("Dunn's Test:\n")
print(dunn_test$comparison)
cat("\n")
}
####ESBL-Ec percentage---------------------
#####Temperature-------------------------------
correlation_results <- list()
alpha <- 0.05  # Set your desired significance level (e.g., 0.05)
for (loc in unique_locations) {
data_loc <- subset(df, df$wwtp == loc)  # Subset data for the specific location
correlation_result <- cor.test(data_loc$average_ESBL_Ec, data_loc$temperature, method = "spearman")
# Apply Bonferroni correction
p_value_corrected <- correlation_result$p.value * length(unique_locations)
significant <- p_value_corrected <= alpha
correlation_results[[loc]] <- list(
correlation_coefficient = correlation_result$estimate,
p_value = correlation_result$p.value,
p_value_corrected = p_value_corrected,
significant = significant
)
}
unique_locations <- unique(df$wwtp) # Unique locations in your dataset
####ESBL-Ec percentage---------------------
#####Temperature-------------------------------
correlation_results <- list()
alpha <- 0.05  # Set your desired significance level (e.g., 0.05)
for (loc in unique_locations) {
data_loc <- subset(df, df$wwtp == loc)  # Subset data for the specific location
correlation_result <- cor.test(data_loc$average_ESBL_Ec, data_loc$temperature, method = "spearman")
# Apply Bonferroni correction
p_value_corrected <- correlation_result$p.value * length(unique_locations)
significant <- p_value_corrected <= alpha
correlation_results[[loc]] <- list(
correlation_coefficient = correlation_result$estimate,
p_value = correlation_result$p.value,
p_value_corrected = p_value_corrected,
significant = significant
)
}
# Access the correlation coefficients, p-values, and corrected p-values for each location
for (loc in unique_locations) {
result <- correlation_results[[loc]]
correlation_coefficient <- result$correlation_coefficient
p_value <- result$p_value
p_value_corrected <- result$p_value_corrected
significant <- result$significant
print(paste("Correlation coefficient for", loc, ":", correlation_coefficient))
print(paste("Raw p-value for", loc, ":", p_value))
print(paste("Bonferroni-corrected p-value for", loc, ":", p_value_corrected))
print(paste("Significant for", loc, ":", significant))
}
#####Precipitation 24h------------------------------
correlation_results <- list()
alpha <- 0.05  # Set your desired significance level (e.g., 0.05)
for (loc in unique_locations) {
data_loc <- subset(df, df$wwtp == loc)  # Subset data for the specific location
correlation_result <- cor.test(data_loc$average_ESBL_Ec, data_loc$precipitations_24h_sum_mm, method = "spearman")
# Apply Bonferroni correction
p_value_corrected <- correlation_result$p.value * length(unique_locations)
significant <- p_value_corrected <= alpha
correlation_results[[loc]] <- list(
correlation_coefficient = correlation_result$estimate,
p_value = correlation_result$p.value,
p_value_corrected = p_value_corrected,
significant = significant
)
}
# Access the correlation coefficients, p-values, and corrected p-values for each location
for (loc in unique_locations) {
result <- correlation_results[[loc]]
correlation_coefficient <- result$correlation_coefficient
p_value <- result$p_value
p_value_corrected <- result$p_value_corrected
significant <- result$significant
print(paste("Correlation coefficient for", loc, ":", correlation_coefficient))
print(paste("Raw p-value for", loc, ":", p_value))
print(paste("Bonferroni-corrected p-value for", loc, ":", p_value_corrected))
print(paste("Significant for", loc, ":", significant))
}
#####Precipitation 96h------------------------------------
correlation_results <- list()
alpha <- 0.05  # Set your desired significance level (e.g., 0.05)
for (loc in unique_locations) {
data_loc <- subset(df, df$wwtp == loc)  # Subset data for the specific location
correlation_result <- cor.test(data_loc$average_ESBL_Ec, data_loc$precipitations_96h_sum_mm, method = "spearman")
# Apply Bonferroni correction
p_value_corrected <- correlation_result$p.value * length(unique_locations)
significant <- p_value_corrected <= alpha
correlation_results[[loc]] <- list(
correlation_coefficient = correlation_result$estimate,
p_value = correlation_result$p.value,
p_value_corrected = p_value_corrected,
significant = significant
)
}
# Access the correlation coefficients, p-values, and corrected p-values for each location
for (loc in unique_locations) {
result <- correlation_results[[loc]]
correlation_coefficient <- result$correlation_coefficient
p_value <- result$p_value
p_value_corrected <- result$p_value_corrected
significant <- result$significant
print(paste("Correlation coefficient for", loc, ":", correlation_coefficient))
print(paste("Raw p-value for", loc, ":", p_value))
print(paste("Bonferroni-corrected p-value for", loc, ":", p_value_corrected))
print(paste("Significant for", loc, ":", significant))
}
#####Plot heatmap--------------------------------------
# Generate df variables
correlation_coefficients <- c(0.394534630931989, 0.450110865205845, 0.234993325880179, 0.320655248832457, -0.149250864559337, 0.160802567895004,
0.12032107193718,-0.358154604398249, -0.115771803283113, -0.281567040706516, 0.0719901192324829, -0.258667627619305,
0.231378437899986,-0.211805457094709, -0.203158048829787, -0.0303622030279818, 0.289718938645438, -0.105004537864799)
p_values <- c(0.0274760373394784, 0.0055169435967361, 0.581584596772695, 0.130704485988326, 1.80547628831787, 1.68147485999875,
2.43140657888691, 0.0591849647310879,2.51107406169802, 0.271940685990817, 3.71590778298805, 0.474940838462424,
0.635613286812865, 0.814067106478304,0.916594316023928,4.99496999327398,0.247621185391402,2.89444421427645)
locations <- c("ARA Altenrhein", "ARA Chur", "STEP d'Aïre Genève", "ARA Sensetal Laupen", "IDA CDA Lugano", "ARA Werdhölzli Zürich",
"ARA Altenrhein", "ARA Chur", "STEP d'Aïre Genève", "ARA Sensetal Laupen", "IDA CDA Lugano", "ARA Werdhölzli Zürich",
"ARA Altenrhein", "ARA Chur", "STEP d'Aïre Genève", "ARA Sensetal Laupen", "IDA CDA Lugano", "ARA Werdhölzli Zürich")
variables <- c( "Temperature (°C)","Temperature (°C)","Temperature (°C)","Temperature (°C)","Temperature (°C)","Temperature (°C)",
"Precipitation (24h sum)","Precipitation (24h sum)","Precipitation (24h sum)","Precipitation (24h sum)","Precipitation (24h sum)","Precipitation (24h sum)",
"Precipitation (96h sum)","Precipitation (96h sum)","Precipitation (96h sum)","Precipitation (96h sum)","Precipitation (96h sum)","Precipitation (96h sum)")
# Generate df for the heatmap
heatmap_data_1 <- data.frame(Location = locations, Variable = variables)
heatmap_data_1$Correlation <- correlation_coefficients
heatmap_data_1$P_Value <- p_values
# Plot heatmap
heatmap_plot <- ggplot(heatmap_data_1, aes(x = Variable, y = Location)) +
geom_tile(aes(fill = Correlation), color = "white") +
geom_text(data = subset(heatmap_data_1, P_Value < 0.05), aes(label = "*"), color = "black", size = 10) +
scale_fill_gradient2(low = "darkred", mid = "white", high = "darkgreen", midpoint = 0, limits = c(-1, 1), na.value = "grey") +
labs(x = "",
y = "",
fill = "Spearman's correlation coefficient") +
theme_minimal() +
ggtitle(expression(paste("Percentage of ESBL- ", italic("E. coli"), " (%)")))+
theme(axis.text.x = element_text(angle = 45, hjust = 1, size=10), axis.text.y=element_text(size = 10))
####Loads ESBL-E. coli--------------
#####Temperature--------------------------------
correlation_results <- list()
heatmap_plot
##CDF, mean and median of Bangladesh ESBL-E.coli percentage in the gut----------------
#Percentage of ESBL-E. coli out of total E. coli in the gut of children
setwd("/Users/conforsh/switchdrive/Institution/Manuscripts/esblec-monitor-ww-21-22/data")
df <- read.csv("intestinal_carriage_bangladesh.csv", header = TRUE)
# Create empirical CDF data
df_bang$ecdf <- ecdf(df_bang$percentage_esblEc)(df_bang$percentage_esblEc)
df_bang <- read.csv("intestinal_carriage_bangladesh.csv", header = TRUE)
# Create empirical CDF data
df_bang$ecdf <- ecdf(df_bang$percentage_esblEc)(df_bang$percentage_esblEc)
# Fit lognormal distribution to data
fit <- fitdistr(df_bang$percentage_esblEc, "lognormal")
# Generate fitted CDF values based on the lognormal parameters
df_bang$lognorm_cdf <- plnorm(df_bang$percentage_esblEc, meanlog = fit$estimate[1], sdlog = fit$estimate[2])
# Calculate empirical arithmetic mean and median
mean_val <- mean(df_bang$percentage_esblEc)
median_val <- median(df_bang$percentage_esblEc)
# Generate Plot
ggplot(df_bang, aes(percentage_esblEc)) +
geom_line(aes(y=ecdf, color="Empirical CDF"), size=1) +
geom_line(aes(y=lognorm_cdf, color="Lognormal CDF"), linetype="solid", size=0.5) +
scale_x_log10(labels = scales::comma) +
theme_minimal() +
theme(
panel.grid.major = element_blank(),
panel.grid.minor = element_blank(),
axis.line = element_line(colour = "black"),
axis.ticks = element_line(colour = "black")
) +
labs(
x = expression(paste("Percentage of ESBL-", italic("E. coli"), " out of total ", italic("E. coli"), " in the gut of children in Bangladesh (%)")),
y = "CDF",
title = paste("Lognormal Parameters: Meanlog =", round(fit$estimate[1], 3),
"Sdlog =", round(fit$estimate[2], 3))) +
geom_textvline(label = "Median = 2%", vjust = 1.3, hjust=0.01,
aes(xintercept = median_val), linetype = "dashed", color="black", alpha =1)+
geom_textvline(label = "Mean = 19.3%", vjust = 1.3, hjust=0.01,
aes(xintercept = mean_val), linetype = "dotted", color="black", alpha =1)+
scale_color_manual("Legend",
values = c("Empirical CDF" = "blue", "Lognormal CDF" = "red"))
# Generate Plot
cdf=ggplot(df_bang, aes(percentage_esblEc)) +
geom_line(aes(y=ecdf, color="Empirical CDF"), size=1) +
geom_line(aes(y=lognorm_cdf, color="Lognormal CDF"), linetype="solid", linewidth=0.5) +
scale_x_log10(labels = scales::comma) +
theme_minimal() +
theme(
panel.grid.major = element_blank(),
panel.grid.minor = element_blank(),
axis.line = element_line(colour = "black"),
axis.ticks = element_line(colour = "black")
) +
labs(
x = expression(paste("Percentage of ESBL-", italic("E. coli"), " out of total ", italic("E. coli"), " in the gut of children in Bangladesh (%)")),
y = "CDF",
title = paste("Lognormal Parameters: Meanlog =", round(fit$estimate[1], 3),
"Sdlog =", round(fit$estimate[2], 3))) +
geom_textvline(label = "Median = 2%", vjust = 1.3, hjust=0.01,
aes(xintercept = median_val), linetype = "dashed", color="black", alpha =1)+
geom_textvline(label = "Mean = 19.3%", vjust = 1.3, hjust=0.01,
aes(xintercept = mean_val), linetype = "dotted", color="black", alpha =1)+
scale_color_manual("Legend",
values = c("Empirical CDF" = "blue", "Lognormal CDF" = "red"))
print(cdf)
